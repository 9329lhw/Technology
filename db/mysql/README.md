# mysql
## php基础
## mysql
### 1.mysql基础整理
#### 1.1 回表
### mysql事务隔离级别
#### 1.Read Uncommitted(读取未提交内容)
    (1)所有事务都可以看到其他未提交事务的执行结果 
    (2)本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少 
    (3)该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据
#### 2.Read Committed(读取提交内容)
    (1)这是大多数数据库系统的默认隔离级别（但不是MySQL默认的） 
    (2)它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变 
    (3)这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着
    我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。 |——>导致这种情况的原因可能有：
    (1)有一个交叉的事务有新的commit，导致了数据的改变;
    (2)一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit
#### 3.Repeatable Read(可重读)
    (1)这是MySQL的默认事务隔离级别 
    (2)它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行 
    (3)此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又
    在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行 
    (4)InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)
    机制解决了幻读
#### 4.Serializable(可串行化)
    (1)这是最高的隔离级别 
    (2)它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的
        数据行上加上共享锁。 
    (3)在这个级别，可能导致大量的超时现象和锁竞争
    
### mysql锁
#### 1.行锁
#### 2.表锁
#### 3.间隙锁（gap）
    说白了gap就是索引树中插入新记录的空隙。相应的gap lock就是加在gap上的锁，
    还有一个next-key锁，是记录+记前面的gap的组合的锁。
##### 3.1 订单如何防止间隙锁：
    1 尽量采用乐观锁，乐观锁是在php等代码层面的锁，就不会锁住数据库资源
    2 事务中update，where后面的字段尽量带上索引，不然间隙锁的范围很大
    3 尽量不要出现长事务，否则事务中更新订单时间隙锁会被锁很久，另一事务插入订单就会执行很久
    4 update订单表，begin和commit之间的时间不要太长，之间不要写一些慢代码，比如请求第三方接口
    5 分表能防止不分表情况下整张表被锁住。分表后是锁住众多表中的其中一张
#### 4.什么是死锁
    所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，
    若无外力作用，它们都将无法再向前推进。
#### 5.死锁怎么解决
    1. 等待，直到超时（innodb_lock_wait_timeout=10s）。
    2. 发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect=on）。
#### 3.如何避免发生死锁
    1. 操作完之后立即提交事务，特别是在交互式命令行中。比如中途不要去请求第三方接口或者
    执行一些慢逻辑，能不放到事务里面的php代码， 就别放到事务里面
    2. 资源一次性分配
        一次性锁协议，事务开始时，即一次性申请所有的锁，之后不会再申请任何锁，如果其中
        某个锁不可用，则整个申请就不成功，事务就不会执行，在事务尾端，一次性释放所有的
        锁。一次性锁协议不会产生死锁的问题，但事务的并发度不高。
    3.尽量采用乐观锁，因为悲观锁都是要求mysql锁资源，而乐观锁不是
    4. 采用超时设置，时间越短，锁等待时间越短。到点就会自动超时，不会继续等待锁释放
    5. 保证没有长事务，长事务尽量拆分成短事务，以为2个短事务很难重合到一起。就是说，
    如果一个事务瞬间执行完毕了，就很好，如果一直没执行完毕， 就很可能另外一个事务
    冲进来二者重合。就加大死锁几率
    6. 修改多个表或者多个行的时候，将修改的顺序保持一致。死锁是因为锁定
    资源的顺序刚好相反。如果顺序是一样的，就不会产生死锁。
    7. 创建索引，可以使创建的锁关联到的数据更少。如果where后面的字段没有索引，
    哪怕只操作一行数据， 也会锁整张表， 因为锁是基于索引的。    
	https://www.cnblogs.com/hhthtt/p/10707541.html
### mysql系统文件
### mysql索引
#### 从数据结构角度
    1、B+树索引(O(log(n)))：关于B+树索引，可以参考 MySQL索引背后的数据结构及算法原理
    2、hash索引：
    a 仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询
    b 其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，
    最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引
    c 只有Memory存储引擎显示支持hash索引
    3、FULLTEXT索引（现在MyISAM和InnoDB引擎都支持了）
    4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）
#### 从物理存储角度
    1、聚集索引（clustered index）
    2、非聚集索引（non-clustered index）
    聚集索引和非聚集索引的区别如下：
    　　1) 聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致，
    聚集索引表记录的排列顺序与索引的排列顺序一致，优点是查询速度快，因为一旦
    具有第一个索引值的纪录被找到，具有连续索引值的记录也一定物理的紧跟其后。
    　　2) 聚集索引的缺点是对表进行修改速度较慢，这是为了保持表中的记录的物理顺序与索
    引的顺序一致，而把记录插入到数据页的相应位置，必须在数据页中进行数据重排，
    降低了执行速度。非聚集索引指定了表中记录的逻辑顺序，但记录的物理顺序和索引的顺序不
    一致，聚集索引和非聚集索引都采用了B+树的结构，但非聚集索引的叶子层并不与实际的
    总结：
    1.聚集索引查找速度比非聚集索引快,聚集索引的排序是顺序的
    2.聚集索引修改比较慢
#### 从逻辑角度
    1、主键索引：主键索引是一种特殊的唯一索引，不允许有空值
    2、普通索引或者单列索引
    3、多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用
    了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
    4、唯一索引或者非唯一索引
    5、空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，
    分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得
    能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT 
    NULL，空间索引只能在存储引擎为MYISAM的表中创建
    CREATE TABLE table_name[col_name data type]
    [unique|fulltext|spatial][index|key][index_name](col_name[length])[asc|desc]
    1、unique|fulltext|spatial为可选参数，分别表示唯一索引、全文索引和空间索引；
    2、index和key为同义词，两者作用相同，用来指定创建索引
    3、col_name为需要创建索引的字段列，该列必须从数据表中该定义的多个列中选择；
    4、index_name指定索引的名称，为可选参数，如果不指定，MYSQL默认col_name为索引值；
    5、length为可选参数，表示索引的长度，只有字符串类型的字段才能指定索引长度；
    6、asc或desc指定升序或降序的索引值存储
### 主从延时
    我们可以使用percona-toolkit工具做校验，而该工具包含 
    1. pt-table-checksum 负责检测MySQL主从数据一致性 
    2. pt-table-sync负责挡住从数据不一致时修复数据，让他们保存数据的一致性 
    3. pt-heartbeat 负责监控MySQL主从同步延迟
### 分库分表
    垂直分库
    水平分库
    垂直分表
    水品分表
    异构索引表
    分库分表使用场景
    1.订单分库分表
### 分布式事务
	https://www.cnblogs.com/jajian/p/10014145.html
	xa事务
	2pc(两阶段提交)：第一次提交时准备操作，第二次提交时真正的提交-------------->产生的问题：数据不一致
    	3pc(三阶段提交)：在2pc的基础上多了一次消息通知的阶段住要 第一次提交完了通知第二次进行提交--------->mysql官方暂时未实现
    	tcc(TCC两阶段补偿型)：在2pc的基础上使用接口来处理事务的回滚操作
	mq(最终一致性，幂等性)：使用rabbit ack高级特性
## 分布式事务行业主要解决方案介绍
#### 两阶段提交（2PC）（two-phase commit protocol）
    第一阶段：请求/表决阶段
    第二阶段：提交/执行阶段（正常流程）
    第二阶段：提交/执行阶段（异常流程）
    遇到的一些问题：
       1.性能问题
       2.协调者单点故障问题
       3.丢失消息导致的数据不一致问题
#### 三阶段提交（3PC）
    三阶段提交又称3PC，其在两阶段提交的基础上增加了CanCommit阶段，
    并引入了超时机制。一旦事务参与者迟迟没有收到协调者的Commit请求，
    就会自动进行本地commit，这样相对有效地解决了协调者单点故障的问题。
    3PC解决了2PC1,2问题但是任然没有完全解决数据不一致的问题
#### 补偿事务（TCC）
    Try阶段：主要是对业务系统做检测及资源预留。
    Confirm阶段：确认执行业务操作。 通过调用确认接口
    Cancel阶段：取消执行业务操作。 通过调用取消接口
    不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此外，
    其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略
#### MQ最终一致性事务
    1 消息百分百投递成功
    结合comfirm机制
    2 消息百分百消费成功
    结合ack机制
    并且要解决幂等性问题
### 高可用
#### MHA
##### 1.MHA原理
    1. 从宕机崩溃的master保存二进制日志事件（binlog events） 
    2. 识别含有最新更新的slave 
    3. 应用差异的中继日志（relay log）到其他的slave；
    4. 应用从master保存的二进制日志事件（binlog events）； 
    5. 提升一个slave为新的master； 
    6. 使其他的slave连接新的master进行复制；

## redis
### redis list,hash,使用比较慢的命令为什么慢
### redis为什么那么快
    
    1.完全基于内存
    2.数据结构简单
    3.采用单线程避免
    4.使用多路io复用模型，非阻塞io
    5.使用底层epoll
#### redis为什么是单线程  
    
    redis的瓶颈最有可能是机器内存或者网络带宽，单线程容易实现且cpu
    不会成为瓶颈那就顺理成章的采用单线程方案
### 主从复制
    全量复制
    1.Redis 内部会发出一个同步命令，刚开始是 Psync 命令，Psync ? -1表示要求 master 主机同步数据
    2.机会向从机发送 runid 和 offset，因为 slave 并没有对应的 offset，所以是全量复制
    3.从机 slave 会保存 主机master 的基本信息 save masterInfo
    4.主节点收到全量复制的命令后，执行bgsave（异步执行），在后台生成RDB文件（快照），并使用一个
    缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令
    5.主机send RDB 发送 RDB 文件给从机
    6.发送缓冲区数据
    7.刷新旧的数据，从节点在载入主节点的数据之前要先将老数据清除
    8.加载 RDB 文件将数据库状态更新至主节点执行bgsave时的数据库状态和缓冲区数据的加载。
![RUNOOB 图标](asset/redismslave.png)

    部分复制
    1.如果网络抖动（连接断开 connection lost）
    2.主机master 还是会写 replbackbuffer（复制缓冲区）
    3.从机slave 会继续尝试连接主机
    4.从机slave 会把自己当前 runid 和偏移量传输给主机 master，并且执行 pysnc 命令同步
    5.如果 master 发现你的偏移量是在缓冲区的范围内，就会返回 continue 命令
    6.同步了 offset 的部分数据，所以部分复制的基础就是偏移量 offset。
![RUNOOB 图标](asset/redismslave_2.png) 
### 持久化
    RDB手可以手动触发和自动触发：
    ·手动触发：save 和 bgsave ，bgsave 是主流的触发 RDB 持久化方式
    ·自动触发：
        # 900s内至少达到一条写命令 save 900 1 
        # 300s内至少达至10条写命令 save 300 10 
        # 60s内至少达到10000条写命令 save 60 10000
    AOF 重写过程可以手动触发和自动触发：
    ·手动触发：直接调用 bgrewriteaof 命令。 
    ·自动触发：根据 auto-aof-rewrite-min-size和auto-aof-rewrite-percentage 参数确定自动触发时机。
### 哨兵原理
    
    1.检测问题，主要讲的是三个定时任务，这三个内部的执行任务可以保证出现问题马上让 Sentinel 知道。 
    2.发现问题，主要讲的是主观下线和客观下线。当有一台 Sentinel 机器发现问题时，它就会主观对它主观下线。 
    但是当多个 Sentinel 都发现有问题的时候，才会出现客观下线。 
    3.找到解决问题的人，主要讲的是领导者选举，如何在 Sentinel 内部多台节点做领导者选举，选出一个领导者。 
    4.解决问题，主要讲的是故障转移，即如何进行故障转移
        1. 三个定时任务
        每10秒每个 Sentinel 对 Master 和 Slave 执行一次 Info Replication 。 
        每2秒每个 Sentinel 通过 Master 节点的 channel 交换信息（pub/sub）。 
        每1秒每个 Sentinel 对其他 Sentinel 和 Redis 执行 pin 
        第一个定时任务，指的是 Redis Sentinel 可以对 Redis 节点做失败判断和故障转移，在 Redis 内部有
        三个定时任务作为基础，来 Info Replication 发现 Slave 节点， 这个命令可以确定主从关系。 
        第二个定时任务，类似于发布订阅， Sentinel 会对主从关系进行判定，通过 sentinel:hello 频道交互。了解
        主从关系可以帮助更好的自动化操作 Redis 。然后 Sentinel 会告知系统消息给其它 Sentinel 节点，最终达到共识，
        同时 Sentinel节点能够互相感知到对方。 
        第三个定时任务，指的是对每个节点和其它 Sentinel 进行心跳检测，它是失败判定的依据
### 集群
#### 集群的几种方式（https://blog.csdn.net/drdongshiye/article/details/84204392）
	一、单节点实例
	二、主从模式（master/slaver）
	三、sentinel模式
	四、cluster模式
### 常见问题
    1.缓存穿透：查询一个数据库一定不存在的数据
    解决：
    1)增加用户鉴权校验
    2）布隆过滤器
    3）设置空值缓存对象
    2.缓存击穿：对于一些设置了过期时间key值如果这些值可能会在某些时间
    点被超高并发的访问，是一种非常“热点”的数据
    解决：
    1）设置热点数据用不过期
    2）加互斥锁
    3）提前加互斥锁，在读取数据时重新更新缓存
    3.缓存雪崩：缓存大量失效，导致大量请求都直接向数据库获取数据，造成数据库
    的压力
    解决；
    1）加锁降低数据库压力
    2）设置redis过期时间上时加一个随机数避免大批数据过期
    3）部署分布式redis，在一台redis服务器故障时，立刻将请求转移到另一台服务器
    4.缓存与数据库双写一致性
    1）先删除缓存，再修改数据库
    2）
## elk
### 

## rabbimq
### 

## kafka
    Kafka为什么那么快？
    1.Cache Filesystem Cache PageCache缓存
    2.顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。
    3.Zero-copy 零拷技术减少拷贝次数
    4.Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。
    5.Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。
### 

## 网络
###  同步，异步，阻塞，非阻塞
    同步：就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。
    异步：和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。
    实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者
    阻塞：意思就是在哪里等待，要等别人执行完成才能往下去执行； 
    非阻塞：就是程序可以不用等待执行的结果， 就可以进行下一步的操作；
### 进程，线程，协成
    进程：进程，直观点说，保存在硬盘上的程序运行以后，会在内存空间里形成一个独立的内存体，
    这个内存体有自己独立的地址空间，有自己的堆，上级挂靠单位是操作系统。操作系统会以进程为单位，
    分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位
    线程：有时被称为轻量级进程(Lightweight Process，LWP），是操作系统调度
    （CPU调度）执行的最小单位
    协程：是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制
    （也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源
### 三次握手
    所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个
    TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在s
    ocket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示：
   
![RUNOOB 图标](asset/3次握手.png)  
    
    （1）第一次握手：
    Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，
    Client进入SYN_SENT状态，等待Server确认。
    （2）第二次握手：
    Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志
    位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给
    Client以确认连接请求，Server进入SYN_RCVD状态。
    （3）第三次握手：
    Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位
    ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，
    ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，
    完成三次握手，随后Client与Server之间可以开始传输数据了。
    
    为什么要3次握手
    防止已过期的连接请求报文突然又传送到服务器，因而产生错误。
### 四次挥手 
    所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，
    需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过
    程由客户端或服务端任一方执行close来触发，整个流程如下图所示：  

![RUNOOB 图标](asset/4次挥手.png)     
    
    第一次挥手：
    Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。
    第二次挥手：
    Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1
    （与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。
    第三次挥手：
    Server发送一个FIN，用来关闭Server到Client的数据传送，
    Server进入LAST_ACK状态。
    第四次挥手：
    Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，
    确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手
    
    	先由客户端向服务器端发送一个FIN，请求关闭数据传输。
	当服务器接收到客户端的FIN时，向客户端发送一个ACK，其中ack的值等于FIN+SEQ
	然后服务器向客户端发送一个FIN，告诉客户端应用程序关闭。
	当客户端收到服务器端的FIN是，回复一个ACK给服务器端。其中ack的值等于FIN+SEQ
    	为什么要4次挥手？
    	确保数据能够完成传输。

	https://www.cnblogs.com/saolv/p/7807677.html
	
### 五大io模型
    阻塞IO：
    非阻塞IO：
    信号驱动IO：
    IO多路转接：
    异步IO：
### 网络模型
    select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，
    也就是说这个读写过程是阻塞的
    https://www.jianshu.com/p/397449cadc9a
    select 
    poll 
    epoll 
    reactor模型
        Reactor模式是处理并发I/O比较常见的一种模式，用于同步I/O，中心思想是将所有
        要处理的I/O事件注册到一个中心I/O多路复用器上，同时主线程/进程阻塞在多路复用器上；
        一旦有I/O事件到来或是准备就绪(文件描述符或socket可读、写)，多路复用器返回并将
        事先注册的相应I/O事件分发到对应的处理器中。
        Reactor是一种事件驱动机制，和普通函数调用的不同之处在于：应用程序不是主动的调用
        某个API完成处理，而是恰恰相反，Reactor逆置了事件处理流程，应用程序需要提供相应
        的接口并注册到Reactor上，如果相应的事件发生，Reactor将主动调用应用程序注册的接
        口，这些接口又称为“回调函数”。用“好莱坞原则”来形容Reactor再合适不过了：不要打电
        话给我们，我们会打电话通知你。
        Reactor模式与Observer模式在某些方面极为相似：当一个主体发生改变时，所有依属体
        都得到通知。不过，观察者模式与单个事件源关联，而反应器模式则与多个事件源关联 。
### 进程间通讯的方式(https://www.cnblogs.com/zgq0/p/8780893.html)
	1.管道：速度慢，容量有限，只有父子进程能通讯    
	2.FIFO：任何进程间都能通讯，但速度慢    
	3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题    
	4.信号量：不能传递复杂消息，只能用来同步    
	5.共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存
### http常见状态码
    301 moved permanently 永久重定向，将用户的访问，重定向到某个url，
    当访问忘记最后加/,将301
    302 found 临时重定向，书签不会变更
    303 see other 临时重定向，希望get方法访问
    304 Not Modified（未修改）客户的缓存资源是最新的，要客户端使用缓存
    400 bad request 请求中有错误语法
    403 forbidden 访问被服务器拒绝，包括文件权限，防火墙等等
    404 not found 没有找到要访问资源
    408 Request Timeout（请求超时）如果客户端完成请求时花费的时间太长， 
    服务器可以回送这个状态码并关闭连接
    409 Conflict（冲突）发出的请求在资源上造成了一些冲突
    407 Proxy Authentication Required(要求进行代理认证) 与状态码401类似， 
    用于需要进行认证的代理服务器
    500 internel erver error 服务端执行请求时发生错误，可能web应用端存在bug
    502 Bad Gateway（网关故障）
    		1.代理使用的服务器遇到了上游的无效响应
    		2.若代理服务器+真实服务器，大部分情况下是真实服务器返回的请求失败，
    		代理服务器才返回502
    503 service unavailable 服务器暂时属于超负载或者正在停机维护，无法处理请求。
    504 Gateway Time-out PHP-CGI已经执行，但是由于某种原因(一般是读取资源的问题)
    没有执行完毕而导致PHP-CGI进程终止。
### 常用的信号量
    SIGKILL 9 终止进程 杀死进程/关闭进程（暴力关闭）
    SIGUSR1 10 终止进程 用户定义信号1 
### 网络安全
    xss
    csrf
    点击劫持
    传输安全(http窃听,http篡改)
    中间人攻击
    密码攻击
    sql注入
    文件上传
    dos攻击
    重放攻击
    cc攻击
    ARP欺骗
    IP欺骗
    SYN攻击：
    在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接
    （half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入
    ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server
    不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，
    因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致
    正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。
    SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接
    状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：
    #netstat -nap | grep SYN_RECV  
    
## 并发
### rps,qps,tps,pv,uv,吞吐量
    rps:代表吞吐率，即 Requests Per Second 的缩写。 
    吞吐率是服务器并发处理能力的量化描述，
    单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。
        并发数/平均响应时间
    tps：每秒查询数，每秒系统能够处理的查询请求次数
    qps: 每秒请求数
        qps>1000可以称为高并发，一般的也就2,300左右也算ok的
        常用的压测工具ab,jmeter
        注：不要对线上数据进行压测
    pv:问量,即页面浏览量或者点击量,用户每次对网站的访问均被记录1次。
    用户对同一页面的多次访问，访问量值累计
    uv:独立访客，将每个独立上网电脑（以cookie为依据）视为一位访客，
    一天之内（00:00-24:00），访问您网站的访客数量。一天之内相同
    cookie的访问只被计算1次
        常键pv,uv检测：
            1.第三方(百度)
            2.nginx访问日志
    吞吐量：单位时间内处理的任务数
    https://www.huaweicloud.com/articles/e69c2d94805734d47a5b86d4f70b7d3b.html

## git
### git有哪些主流的工作流
#### 1.集中式工作流
类似于集中式版本控制，以中央仓库作为项目所有修改的单点实体，在git中我们使用master
分支作为主干分支，所有修改都提交到master上，在集中式工作流中我们只使用master。
#### 2.功能分支工作流
不在master分支上做开发，每个功能模块基于一个专门的分支。功能开发促成了Pull Request 
工作流，每个PR让技术负责人review代码，检查无误后merge到master分支上。
#### 3.Git flow工作流
远程仓库作为开发者的交互中心，同时围绕master、release、develop、feature
feature是统称不止这一个）四种分支协作，完成多环境、多任务的代码管理。
#### 4.Github工作流